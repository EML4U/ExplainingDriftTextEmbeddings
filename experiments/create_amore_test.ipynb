{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "deduplicated data:\n",
    "- generator notebook: filtering-deduplication.ipynb\n",
    "- ftp: https://hobbitdata.informatik.uni-leipzig.de/EML4U/2022-02-15-Benchmark-deduplicated/\n",
    "- file system: /home/eml4u/EML4U/data/benchmark/deduplicated.pickle.bz2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read deduplicated reviews numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_duplicates = '/home/eml4u/EML4U/data/benchmark/deduplicated.pickle.bz2'\n",
    "\n",
    "# Read deduplicated review Ids\n",
    "with bz2.BZ2File(file_duplicates, 'r') as file:\n",
    "    dup_ids = pickle.loads(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print overview\n",
    "count = 0\n",
    "first = None\n",
    "for year in dup_ids:\n",
    "    for star in dup_ids[year]:\n",
    "        size = len(dup_ids[year][star])\n",
    "        print(year, star, size)\n",
    "        count += size\n",
    "        if first is None:\n",
    "            first = dup_ids[year][star][0]\n",
    "print('size: ' + str(count)) # size: 1727821\n",
    "print('first item:', first)  # first item: [16505, 2007, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# amore_test_1\n",
    "\n",
    "10,000 1/5-star items from 2007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    \n",
    "    # Extract\n",
    "    amore_test_1 = {}\n",
    "    amore_test_1[0] = []\n",
    "    amore_test_1[1] = []\n",
    "    size = 10 * 1000\n",
    "    year = 2007\n",
    "\n",
    "    star = 1\n",
    "    for i, item in enumerate(dup_ids[year][star]):\n",
    "        if(i < size):\n",
    "            amore_test_1[0].append(item[0])\n",
    "\n",
    "    star = 5\n",
    "    for i, item in enumerate(dup_ids[year][star]):\n",
    "        if(i < size):\n",
    "            amore_test_1[1].append(item[0])\n",
    "\n",
    "    print('len(amore_test_1[0]):', len(amore_test_1[0]))\n",
    "    print('len(amore_test_1[1]):', len(amore_test_1[1]))\n",
    "\n",
    "\n",
    "    # Write /tmp/amore_test_1.pickle\n",
    "    import tempfile\n",
    "    import os\n",
    "    file = os.path.join(tempfile.gettempdir(), 'amore_test_1.pickle')\n",
    "    print(file)\n",
    "    with open(file, \"wb\") as f:\n",
    "        pickle.dump(amore_test_1, f)\n",
    "\n",
    "\n",
    "    # Test\n",
    "    with open(file, \"rb\") as f:\n",
    "        test = pickle.load(f)\n",
    "    print('len(test[0]):', len(test[0]))\n",
    "    print('len(test[1]):', len(test[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# amore_test_2\n",
    "\n",
    "- 2011: 25K positive and 25K negative\n",
    "- 2012: 40K positive and 10K negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('2011 1', len(dup_ids[2011][1]))\n",
    "print('2011 2', len(dup_ids[2011][2]))\n",
    "print('2011 4', len(dup_ids[2011][4]))\n",
    "print('2011 5', len(dup_ids[2011][5]))\n",
    "print('2011 neg', len(dup_ids[2011][1]) + len(dup_ids[2011][2]), 25000)\n",
    "print('2011 pos', len(dup_ids[2011][4]) + len(dup_ids[2011][5]), 25000)\n",
    "\n",
    "print('2012 1', len(dup_ids[2012][1]))\n",
    "print('2012 2', len(dup_ids[2012][2]))\n",
    "print('2012 4', len(dup_ids[2012][4]))\n",
    "print('2012 5', len(dup_ids[2012][5]))\n",
    "print('2012 neg', len(dup_ids[2012][1]) + len(dup_ids[2012][2]), 10000)\n",
    "print('2012 pos', len(dup_ids[2012][4]) + len(dup_ids[2012][5]), 40000)\n",
    "\n",
    "if True:\n",
    "    \n",
    "    # Extract\n",
    "    amore_test_2 = {}\n",
    "    amore_test_2[0] = []\n",
    "    amore_test_2[1] = []\n",
    "\n",
    "    size = 25 * 1000\n",
    "    year = 2011\n",
    "    star = 1\n",
    "    for i, item in enumerate(dup_ids[year][star]):\n",
    "        if(len(amore_test_2[0]) < size):\n",
    "            amore_test_2[0].append(item[0])\n",
    "    print('TMP len(amore_test_2[0]):', len(amore_test_2[0]))\n",
    "    star = 2\n",
    "    for i, item in enumerate(dup_ids[year][star]):\n",
    "        if(len(amore_test_2[0]) < size):\n",
    "            amore_test_2[0].append(item[0])\n",
    "    print('TMP len(amore_test_2[0]):', len(amore_test_2[0]))\n",
    "\n",
    "    size = 50 * 1000\n",
    "    year = 2011\n",
    "    star = 5\n",
    "    for i, item in enumerate(dup_ids[year][star]):\n",
    "        if(len(amore_test_2[0]) < size):\n",
    "            amore_test_2[0].append(item[0])\n",
    "    print('TMP len(amore_test_2[0]):', len(amore_test_2[0]))\n",
    "\n",
    "    size = 10 * 1000\n",
    "    year = 2012\n",
    "    star = 1\n",
    "    for i, item in enumerate(dup_ids[year][star]):\n",
    "        if(len(amore_test_2[1]) < size):\n",
    "            amore_test_2[1].append(item[0])\n",
    "    print('TMP len(amore_test_2[1]):', len(amore_test_2[1]))\n",
    "\n",
    "    size = 50 * 1000\n",
    "    year = 2012\n",
    "    star = 5\n",
    "    for i, item in enumerate(dup_ids[year][star]):\n",
    "        if(len(amore_test_2[1]) < size):\n",
    "            amore_test_2[1].append(item[0])\n",
    "    print('TMP len(amore_test_2[1]):', len(amore_test_2[1]))\n",
    "\n",
    "    print('len(amore_test_2[0]):', len(amore_test_2[0]))\n",
    "    print('len(amore_test_2[1]):', len(amore_test_2[1]))\n",
    "\n",
    "\n",
    "    # Write /tmp/amore_test_2.pickle\n",
    "    import tempfile\n",
    "    import os\n",
    "    file = os.path.join(tempfile.gettempdir(), 'amore_test_2.pickle')\n",
    "    print(file)\n",
    "    with open(file, \"wb\") as f:\n",
    "        pickle.dump(amore_test_2, f)\n",
    "\n",
    "\n",
    "    # Test\n",
    "    with open(file, \"rb\") as f:\n",
    "        test = pickle.load(f)\n",
    "    print('len(test[0]):', len(test[0]))\n",
    "    print('len(test[1]):', len(test[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AmoreDoctovecReader tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload \n",
    "import sys\n",
    "sys.path.insert(0, '../access')\n",
    "from amazon_doc2vec_reader import AmoreDoctovecReader\n",
    "amazon_doc2vec_reader = AmoreDoctovecReader()\n",
    "options = {}\n",
    "options['data_directory'] = '/home/eml4u/EML4U/data/amazon-complete'\n",
    "options['distributions_file'] = '/tmp/amore_test_1.pickle'\n",
    "amazon_doc2vec_reader.initialize(options)\n",
    "\n",
    "print(amazon_doc2vec_reader.get_distribution_ids())\n",
    "#print(amazon_doc2vec_reader.get_item_ids(1))\n",
    "#print(amazon_doc2vec_reader.get_text(382))\n",
    "#print(amazon_doc2vec_reader.get_embeddings(382))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Doc2Vec / texts example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra: Read an example (with mapping item ID to raw ID)\n",
    "if True:\n",
    "    # see https://github.com/EML4U/ExplainingDriftTextEmbeddings/blob/2820a1f6825b763ca72b1ca2272e2787af717b90/access/amazon_pickle_reader.py#L68\n",
    "    import sys\n",
    "    sys.path.insert(0, '../access')\n",
    "    from amazon_pickle_reader import AmazonPickleReader\n",
    "    \n",
    "    # see https://hobbitdata.informatik.uni-leipzig.de/EML4U/2022-02-05-DriftExplanationPaper/\n",
    "    reader = AmazonPickleReader('../data/clustering/')\n",
    "    \n",
    "    # Text\n",
    "    if False:\n",
    "        print('raw size:', len(reader.get_all_raw()[1]))\n",
    "        raw_id = reader.get_raw_id(first[0])\n",
    "        print('raw_id:', raw_id)                       # raw_id: 3598690\n",
    "        print(reader.get_text(raw_id))                 # Here's an idea Don't bother [...]\n",
    "        print(reader.get_text(raw_id, metadata=True))  # ['12/17', 2, datetime.datetime(2007, 5, 22, 2, 0), 16505, 3598690]\n",
    "                                                       # 16505*9+1: 148544 (9 lines per item in movies.txt) -> OK\n",
    "    \n",
    "    # Bag of Words / Doc2Vec\n",
    "    if True:\n",
    "        # Direct, without reading the text file (in case of less memory)\n",
    "        raw_id = 3598690\n",
    "        print(reader.get_bow50(raw_id))                # [ 0.5525319   0.02616217  0.6060259  -0.03047042  ...\n",
    "        print(reader.get_bow50(raw_id, metadata=True)) # ['12/17', 2, datetime.datetime(2007, 5, 22, 2, 0), 16505, 3598690]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (EML4U)",
   "language": "python",
   "name": "eml4u"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
