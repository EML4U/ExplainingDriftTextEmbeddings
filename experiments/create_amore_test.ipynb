{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "deduplicated data:\n",
    "- generator notebook: filtering-deduplication.ipynb\n",
    "- ftp: https://hobbitdata.informatik.uni-leipzig.de/EML4U/2022-02-15-Benchmark-deduplicated/\n",
    "- file system: /home/eml4u/EML4U/data/benchmark/deduplicated.pickle.bz2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read deduplicated reviews numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_duplicates = '/home/eml4u/EML4U/data/benchmark/deduplicated.pickle.bz2'\n",
    "\n",
    "# Read deduplicated review Ids\n",
    "with bz2.BZ2File(file_duplicates, 'r') as file:\n",
    "    dup_ids = pickle.loads(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2007 3 13932\n",
      "2007 5 108952\n",
      "2007 4 37664\n",
      "2007 1 11125\n",
      "2007 2 8067\n",
      "2006 5 71619\n",
      "2006 1 9943\n",
      "2006 4 27917\n",
      "2006 2 7050\n",
      "2006 3 11322\n",
      "2008 2 8417\n",
      "2008 5 104455\n",
      "2008 3 13944\n",
      "2008 4 36838\n",
      "2008 1 12661\n",
      "2003 5 32416\n",
      "2003 4 13466\n",
      "2003 3 5860\n",
      "2003 1 3689\n",
      "2003 2 3364\n",
      "2002 5 29576\n",
      "2002 4 12257\n",
      "2002 3 5064\n",
      "2002 1 3597\n",
      "2002 2 3048\n",
      "2004 5 46222\n",
      "2004 4 19364\n",
      "2004 2 4880\n",
      "2004 1 6643\n",
      "2004 3 8592\n",
      "2000 5 25204\n",
      "2000 4 9832\n",
      "2000 1 2512\n",
      "2000 2 2162\n",
      "2000 3 3932\n",
      "2009 5 112998\n",
      "2009 4 37089\n",
      "2009 3 14835\n",
      "2009 2 8846\n",
      "2009 1 14150\n",
      "2011 3 16796\n",
      "2011 5 130571\n",
      "2011 4 40392\n",
      "2011 1 19132\n",
      "2011 2 11363\n",
      "2010 5 113957\n",
      "2010 1 15822\n",
      "2010 3 14925\n",
      "2010 4 36408\n",
      "2010 2 9536\n",
      "2001 5 26294\n",
      "2001 3 4562\n",
      "2001 4 11216\n",
      "2001 1 3015\n",
      "2001 2 2541\n",
      "2005 4 25958\n",
      "2005 5 64445\n",
      "2005 3 11420\n",
      "2005 1 10413\n",
      "2005 2 7053\n",
      "2012 5 134571\n",
      "2012 3 17593\n",
      "2012 4 40528\n",
      "2012 1 21570\n",
      "2012 2 12041\n",
      "1999 4 2166\n",
      "1999 5 7266\n",
      "1999 3 880\n",
      "1999 2 437\n",
      "1999 1 597\n",
      "1998 5 561\n",
      "1998 4 146\n",
      "1998 1 26\n",
      "1998 2 30\n",
      "1998 3 65\n",
      "1997 5 14\n",
      "1997 1 2\n",
      "1997 3 1\n",
      "1997 4 4\n",
      "size: 1727821\n",
      "first item: [16505, 2007, 3]\n"
     ]
    }
   ],
   "source": [
    "# Print overview\n",
    "count = 0\n",
    "first = None\n",
    "for year in dup_ids:\n",
    "    for star in dup_ids[year]:\n",
    "        size = len(dup_ids[year][star])\n",
    "        print(year, star, size)\n",
    "        count += size\n",
    "        if first is None:\n",
    "            first = dup_ids[year][star][0]\n",
    "print('size: ' + str(count)) # size: 1727821\n",
    "print('first item:', first)  # first item: [16505, 2007, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# amore_test_1\n",
    "\n",
    "10,000 1/5-star items from 2007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(amore_test_1[0]): 10000\n",
      "len(amore_test_1[1]): 10000\n",
      "/tmp/amore_test_1.pickle\n",
      "len(test[0]): 10000\n",
      "len(test[1]): 10000\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    \n",
    "    # Extract\n",
    "    amore_test_1 = {}\n",
    "    amore_test_1[0] = []\n",
    "    amore_test_1[1] = []\n",
    "    size = 10 * 1000\n",
    "    year = 2007\n",
    "\n",
    "    star = 1\n",
    "    for i, item in enumerate(dup_ids[year][star]):\n",
    "        if(i < size):\n",
    "            amore_test_1[0].append(item[0])\n",
    "\n",
    "    star = 5\n",
    "    for i, item in enumerate(dup_ids[year][star]):\n",
    "        if(i < size):\n",
    "            amore_test_1[1].append(item[0])\n",
    "\n",
    "    print('len(amore_test_1[0]):', len(amore_test_1[0]))\n",
    "    print('len(amore_test_1[1]):', len(amore_test_1[1]))\n",
    "\n",
    "\n",
    "    # Write /tmp/amore_test_1.pickle\n",
    "    import tempfile\n",
    "    import os\n",
    "    file = os.path.join(tempfile.gettempdir(), 'amore_test_1.pickle')\n",
    "    print(file)\n",
    "    with open(file, \"wb\") as f:\n",
    "        pickle.dump(amore_test_1, f)\n",
    "\n",
    "\n",
    "    # Test\n",
    "    with open(file, \"rb\") as f:\n",
    "        test = pickle.load(f)\n",
    "    print('len(test[0]):', len(test[0]))\n",
    "    print('len(test[1]):', len(test[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AmoreDoctovecReader tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload \n",
    "import sys\n",
    "sys.path.insert(0, '../access')\n",
    "from amazon_doc2vec_reader import AmoreDoctovecReader\n",
    "amazon_doc2vec_reader = AmoreDoctovecReader()\n",
    "options = {}\n",
    "options['data_directory'] = '/home/eml4u/EML4U/data/amazon-complete'\n",
    "options['distributions_file'] = '/tmp/amore_test_1.pickle'\n",
    "amazon_doc2vec_reader.initialize(options)\n",
    "\n",
    "print(amazon_doc2vec_reader.get_distribution_ids())\n",
    "#print(amazon_doc2vec_reader.get_item_ids(1))\n",
    "#print(amazon_doc2vec_reader.get_text(382))\n",
    "#print(amazon_doc2vec_reader.get_embeddings(382))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Doc2Vec / texts example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.5525319   0.02616217  0.6060259  -0.03047042  0.02293159 -0.25403637\n",
      " -0.29787368 -0.22056906  0.20765181 -0.05821491 -0.18668139 -0.06956059\n",
      " -0.8318227   1.3696653   0.49804536  0.14232813 -0.02605313  0.15285726\n",
      "  0.205538    0.5685174   0.19225411  0.79819655 -0.19124962 -0.47846773\n",
      " -0.35822442  0.17535865  0.5258098   0.27033833 -0.15388906 -0.06002378\n",
      " -0.15234096 -0.40373906 -0.0075666   0.9108853  -0.65085965 -1.2872458\n",
      " -0.5022389   0.37863645 -0.17936476  0.1966911   0.31306928 -0.1586144\n",
      " -0.27085486  0.7231196   0.2140226   1.0116422  -0.5624211  -0.11729185\n",
      "  0.5460275  -0.6695958 ]\n",
      "['12/17', 2, datetime.datetime(2007, 5, 22, 2, 0), 16505, 3598690]\n"
     ]
    }
   ],
   "source": [
    "# Extra: Read an example (with mapping item ID to raw ID)\n",
    "if True:\n",
    "    # see https://github.com/EML4U/ExplainingDriftTextEmbeddings/blob/2820a1f6825b763ca72b1ca2272e2787af717b90/access/amazon_pickle_reader.py#L68\n",
    "    import sys\n",
    "    sys.path.insert(0, '../access')\n",
    "    from amazon_pickle_reader import AmazonPickleReader\n",
    "    \n",
    "    # see https://hobbitdata.informatik.uni-leipzig.de/EML4U/2022-02-05-DriftExplanationPaper/\n",
    "    reader = AmazonPickleReader('../data/clustering/')\n",
    "    \n",
    "    # Text\n",
    "    if False:\n",
    "        print('raw size:', len(reader.get_all_raw()[1]))\n",
    "        raw_id = reader.get_raw_id(first[0])\n",
    "        print('raw_id:', raw_id)                       # raw_id: 3598690\n",
    "        print(reader.get_text(raw_id))                 # Here's an idea Don't bother [...]\n",
    "        print(reader.get_text(raw_id, metadata=True))  # ['12/17', 2, datetime.datetime(2007, 5, 22, 2, 0), 16505, 3598690]\n",
    "                                                       # 16505*9+1: 148544 (9 lines per item in movies.txt) -> OK\n",
    "    \n",
    "    # Bag of Words / Doc2Vec\n",
    "    if True:\n",
    "        # Direct, without reading the text file (in case of less memory)\n",
    "        raw_id = 3598690\n",
    "        print(reader.get_bow50(raw_id))                # [ 0.5525319   0.02616217  0.6060259  -0.03047042  ...\n",
    "        print(reader.get_bow50(raw_id, metadata=True)) # ['12/17', 2, datetime.datetime(2007, 5, 22, 2, 0), 16505, 3598690]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (EML4U)",
   "language": "python",
   "name": "eml4u"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
